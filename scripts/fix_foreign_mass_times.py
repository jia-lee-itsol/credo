#!/usr/bin/env python3
"""
massTime í…ìŠ¤íŠ¸ì™€ foreignMassTimes ë°ì´í„° ë¶ˆì¼ì¹˜ë¥¼ ì°¾ì•„ì„œ ìˆ˜ì •í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os
import re

PARISHES_DIR = "../assets/data/parishes"

# ì–¸ì–´ í‚¤ì›Œë“œ ë§¤í•‘
LANGUAGE_KEYWORDS = {
    'EN': ['è‹±èª', 'English', '(è‹±èª)', 'ï¼ˆè‹±èªï¼‰'],
    'ES': ['ã‚¹ãƒšã‚¤ãƒ³èª', 'Spanish', 'EspaÃ±ol', '(ã‚¹ãƒšã‚¤ãƒ³èª)', 'ï¼ˆã‚¹ãƒšã‚¤ãƒ³èªï¼‰'],
    'KR': ['éŸ“å›½èª', 'Korean', '(éŸ“å›½èª)', 'ï¼ˆéŸ“å›½èªï¼‰'],
    'CN': ['ä¸­å›½èª', 'Chinese', 'ä¸­æ–‡', '(ä¸­å›½èª)', 'ï¼ˆä¸­å›½èªï¼‰'],
    'PT': ['ãƒãƒ«ãƒˆã‚¬ãƒ«èª', 'Portuguese', 'PortuguÃªs', '(ãƒãƒ«ãƒˆã‚¬ãƒ«èª)', 'ï¼ˆãƒãƒ«ãƒˆã‚¬ãƒ«èªï¼‰'],
    'VI': ['ãƒ™ãƒˆãƒŠãƒ èª', 'Vietnamese', '(ãƒ™ãƒˆãƒŠãƒ èª)', 'ï¼ˆãƒ™ãƒˆãƒŠãƒ èªï¼‰'],
    'PH': ['ãƒ•ã‚£ãƒªãƒ”ãƒ³èª', 'Filipino', 'Tagalog', '(ãƒ•ã‚£ãƒªãƒ”ãƒ³èª)', 'ï¼ˆãƒ•ã‚£ãƒªãƒ”ãƒ³èªï¼‰'],
    'ID': ['ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èª', 'Indonesian', '(ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èª)', 'ï¼ˆã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èªï¼‰'],
}

def extract_foreign_masses_from_text(mass_time_text):
    """massTime í…ìŠ¤íŠ¸ì—ì„œ ì™¸êµ­ì–´ ë¯¸ì‚¬ ì •ë³´ë¥¼ ì¶”ì¶œ"""
    if not mass_time_text:
        return []

    foreign_masses = []

    # ê° ì–¸ì–´ë³„ë¡œ ê²€ìƒ‰
    for lang_code, keywords in LANGUAGE_KEYWORDS.items():
        for keyword in keywords:
            if keyword in mass_time_text:
                # í•´ë‹¹ í‚¤ì›Œë“œ ì£¼ë³€ì—ì„œ ì‹œê°„ê³¼ ë…¸íŠ¸ ì¶”ì¶œ
                # íŒ¨í„´: ì‹œê°„(HH:MM) + ì–¸ì–´ ë˜ëŠ” ì–¸ì–´ + ì‹œê°„
                patterns = [
                    # 14:00(è‹±èª) ë˜ëŠ” 14:00ï¼ˆè‹±èªï¼‰
                    rf'(\d{{1,2}}:\d{{2}})\s*[ï¼ˆ(]{keyword}[)ï¼‰]',
                    rf'(\d{{1,2}}:\d{{2}})\s*{keyword}',
                    # ç¬¬1æ—¥æ›œ14:00(è‹±èª)
                    rf'(ç¬¬[\dï¼‘ï¼’ï¼“ï¼”]+[ãƒ»,ã€]?ç¬¬?[\dï¼‘ï¼’ï¼“ï¼”]*æ—¥æ›œ?)\s*(\d{{1,2}}:\d{{2}})\s*[ï¼ˆ(]?{keyword}',
                    # è‹±èªãƒŸã‚µ14:00
                    rf'{keyword}ãƒŸã‚µ\s*(\d{{1,2}}:\d{{2}})',
                    # 14:00è‹±èªãƒŸã‚µ
                    rf'(\d{{1,2}}:\d{{2}})\s*{keyword}ãƒŸã‚µ',
                ]

                for pattern in patterns:
                    matches = re.finditer(pattern, mass_time_text)
                    for match in matches:
                        groups = match.groups()
                        time_val = None
                        note_val = ""

                        for g in groups:
                            if g and re.match(r'\d{1,2}:\d{2}', g):
                                time_val = g
                            elif g and 'æ—¥' in g:
                                note_val = g

                        if time_val:
                            # ì¤‘ë³µ ì²´í¬
                            exists = any(
                                fm['language'] == lang_code and fm['time'] == time_val
                                for fm in foreign_masses
                            )
                            if not exists:
                                foreign_masses.append({
                                    'time': time_val,
                                    'language': lang_code,
                                    'note': note_val
                                })
                break  # í•œ ì–¸ì–´ì—ì„œ í‚¤ì›Œë“œ ë°œê²¬í•˜ë©´ ë‹¤ìŒ ì–¸ì–´ë¡œ

    return foreign_masses

def get_existing_foreign_masses(parish):
    """ê¸°ì¡´ foreignMassTimesì—ì„œ ì™¸êµ­ì–´ ë¯¸ì‚¬ ëª©ë¡ ì¶”ì¶œ"""
    foreign_mass_times = parish.get('foreignMassTimes', {})
    existing = []

    for day, masses in foreign_mass_times.items():
        if isinstance(masses, list):
            for mass in masses:
                if isinstance(mass, dict):
                    existing.append({
                        'day': day,
                        'time': mass.get('time', ''),
                        'language': mass.get('language', ''),
                        'note': mass.get('note', '')
                    })

    return existing

def compare_masses(text_masses, existing_masses):
    """í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œí•œ ë¯¸ì‚¬ì™€ ê¸°ì¡´ ë°ì´í„° ë¹„êµ"""
    text_set = set()
    for m in text_masses:
        text_set.add((m['language'], m['time']))

    existing_set = set()
    for m in existing_masses:
        existing_set.add((m['language'], m['time']))

    missing_in_data = text_set - existing_set  # í…ìŠ¤íŠ¸ì—ëŠ” ìˆì§€ë§Œ ë°ì´í„°ì— ì—†ëŠ” ê²ƒ
    extra_in_data = existing_set - text_set    # ë°ì´í„°ì—ëŠ” ìˆì§€ë§Œ í…ìŠ¤íŠ¸ì— ì—†ëŠ” ê²ƒ

    return missing_in_data, extra_in_data

def analyze_parish(parish):
    """ê°œë³„ ì„±ë‹¹ ë¶„ì„"""
    name = parish.get('name', 'Unknown')
    mass_time = parish.get('massTime', '')

    # ì™¸êµ­ì–´ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
    has_foreign = False
    for keywords in LANGUAGE_KEYWORDS.values():
        for kw in keywords:
            if kw in mass_time:
                has_foreign = True
                break
        if has_foreign:
            break

    if not has_foreign:
        return None

    text_masses = extract_foreign_masses_from_text(mass_time)
    existing_masses = get_existing_foreign_masses(parish)

    missing, extra = compare_masses(text_masses, existing_masses)

    if missing or extra:
        return {
            'name': name,
            'massTime': mass_time,
            'text_masses': text_masses,
            'existing_masses': existing_masses,
            'missing_in_data': list(missing),
            'extra_in_data': list(extra)
        }

    return None

def process_all_parishes():
    """ëª¨ë“  ì„±ë‹¹ íŒŒì¼ ì²˜ë¦¬"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    parishes_dir = os.path.join(script_dir, PARISHES_DIR)

    issues = []

    for filename in sorted(os.listdir(parishes_dir)):
        if filename.endswith('.json') and filename != 'dioceses.json':
            filepath = os.path.join(parishes_dir, filename)

            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if 'parishes' not in data:
                continue

            for parish in data['parishes']:
                issue = analyze_parish(parish)
                if issue:
                    issue['file'] = filename
                    issues.append(issue)

    return issues

def main():
    print("ì™¸êµ­ì–´ ë¯¸ì‚¬ ë°ì´í„° ë¶ˆì¼ì¹˜ ë¶„ì„ ì¤‘...\n")

    issues = process_all_parishes()

    if not issues:
        print("ë¶ˆì¼ì¹˜ ì—†ìŒ!")
        return

    print(f"ì´ {len(issues)}ê°œ ì„±ë‹¹ì—ì„œ ë¶ˆì¼ì¹˜ ë°œê²¬:\n")
    print("=" * 80)

    for issue in issues:
        print(f"\nğŸ“ {issue['name']} ({issue['file']})")
        print(f"   massTime: {issue['massTime'][:100]}...")

        if issue['missing_in_data']:
            print(f"   âŒ foreignMassTimesì— ëˆ„ë½ëœ í•­ëª©:")
            for lang, time in issue['missing_in_data']:
                print(f"      - {lang} {time}")

        if issue['extra_in_data']:
            print(f"   âš ï¸  foreignMassTimesì— ìˆì§€ë§Œ massTimeì— ì—†ëŠ” í•­ëª©:")
            for lang, time in issue['extra_in_data']:
                print(f"      - {lang} {time}")

        print(f"   í˜„ì¬ foreignMassTimes: {issue['existing_masses']}")

if __name__ == "__main__":
    main()
